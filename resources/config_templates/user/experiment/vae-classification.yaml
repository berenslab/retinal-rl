# @package _global_
defaults:
  - _self_
  - override /dataset: cifar10
  - override /brain: vae-classifier
  - override /optimizer: vae-classification

# Main experiment configuration for VAE classification
framework: classification

logging:
  use_wandb: True
  project_name: "retinal-vae"
  experiment_name: "vae-classification"

### VAE-specific Parameters ###

# Latent space configuration
latent_dim: 128  # Size of the VAE latent space

# Multi-objective loss weights (from your equation)
lambda_recon: 1.0   # Weight for reconstruction loss
lambda_ib: 0.01     # Weight for KL divergence (information bottleneck)

### Standard Parameters ###

# Vision parameters
vision_height: 216
vision_width: 216

generic_stride: 3
# Training parameters
weight_decay: 0.00001
sparsity_weight: 0.00001

# Architecture parameters
activation: "gelu"

# Retinal circuit kernel sizes
bp_kernel_size: 15    # Bipolar cell kernel
rgc_kernel_size: 11   # Retinal ganglion cell kernel
lgn_kernel_size: 3    # Lateral geniculate nucleus kernel
v1_kernel_size: 9     # V1 kernel

# Layer-wise reconstruction weights
# These control how much each layer contributes to reconstruction
recon_weight_retina: 0.9
recon_weight_thalamus: 0.9
recon_weight_cortex: 0.9

# Architectural Bottleneck
bottleneck_chans: 8
bottleneck_stride: 1


# Normalization settings
layer_norm: True
affine_norm: True

# Training configuration
training:
  batch_size: 128
  num_workers: 4
  
# Evaluation configuration
evaluation:
  batch_size: 256
  num_workers: 4
  
# Analysis configuration
analysis:
  save_reconstructions: True
  reconstruction_frequency: 10  # Save reconstructions every N epochs
  num_reconstruction_samples: 8
