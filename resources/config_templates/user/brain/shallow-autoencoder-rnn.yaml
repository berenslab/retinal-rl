# Configuration for a retinal classifier neural network

# Define the input sensor
sensors:
  vision: # Vision is a list of 3 elements
    - 3  # Number of color channels
    - ${vision_height}  # Height of the input image
    - ${vision_width}  # Width of the input image
  rnn_state:
    - ${rnn_size}  # Size of the RNN state

# Define how the various NeuralCircuits are connected to each other
connections:
  - ["vision", "retina"]  # Input to retina
  - ["retina","thalamus"]  # Retina to thalamus
  - ["thalamus","visual_cortex"]  # Thalamus to visual cortex
  - ["visual_cortex", "prefrontal"]  # Visual cortex to prefrontal cortex
  - ["prefrontal", "rnn"]  # Prefrontal cortex to recurrent network
  - ["rnn_state", "rnn"]  # recurrent input to rnn
  - ["rnn", "actor"]  # recurrent to actor
  - ["rnn", "critic"]  # recurrent to critic
  - ["visual_cortex", "v1_decoder"]  # v1 to decoder (for reconstruction)

# Define the individual nodes (neural circuits) of the network. Many circuit
# parameters are interpolated from the experiment config.
circuits:
  # Retina: initial processing of visual input
  retina:
    _target_: retinal_rl.models.circuits.convolutional.ConvolutionalEncoder
    num_layers: 2
    num_channels: [16,32]  # Two layers with 16 and 32 channels
    kernel_size: 
      - ${bp_kernel_size}
      - ${rgc_kernel_size}
    stride: ${generic_stride}
    activation: ${activation}
    layer_names: ["bipolar", "retinal_ganglion"]  # Names inspired by retinal cell types
    layer_norm: ${layer_norm}
    affine_norm: ${affine_norm}

  # Thalamus: relay and processing station
  thalamus:
    _target_: retinal_rl.models.circuits.convolutional.ConvolutionalEncoder
    num_layers: 1
    num_channels: ${bottleneck_chans}
    kernel_size: ${lgn_kernel_size}
    stride: ${bottleneck_stride}
    activation: ${activation}
    layer_names: ["lgn"]  # Lateral Geniculate Nucleus
    layer_norm: ${layer_norm}
    affine_norm: ${affine_norm}

  # Visual Cortex: higher-level visual processing
  visual_cortex:
    _target_: retinal_rl.models.circuits.convolutional.ConvolutionalEncoder
    num_layers: 1
    num_channels: 64
    kernel_size: ${v1_kernel_size}
    stride: ${generic_stride}
    activation: ${activation}
    layer_names: ["v1"]  # Primary Visual Cortex
    layer_norm: ${layer_norm}
    affine_norm: ${affine_norm}

  # Prefrontal Cortex: high-level cognitive processing
  prefrontal:
    _target_: retinal_rl.models.circuits.fully_connected.FullyConnected
    output_shape:
      - 128  # Size of the latent representation
    hidden_units: 
      - 64  # Number of hidden units
    activation: ${activation}
  
  rnn:
    _target_: retinal_rl.models.circuits.latent_core.LatentRNN
    rnn_size: ${rnn_size}
    rnn_num_layers: 1

  # Decoder: for reconstructing the input from the latent representation
  v1_decoder:
    _target_: retinal_rl.models.circuits.convolutional.ConvolutionalDecoder
    num_layers: 4
    layer_norm: ${layer_norm}
    affine_norm: ${affine_norm}
    num_channels: 
      - ${bottleneck_chans}
      - 32
      - 16
      - 3  # For a symmetric encoder, this should be the reverse of the num_channels in the CNN layers up to the point of decoding (in this case, the thalamus)
    kernel_size: 
      - ${v1_kernel_size}
      - ${lgn_kernel_size}
      - ${rgc_kernel_size}
      - ${bp_kernel_size}
    stride:
      - ${generic_stride}
      - ${bottleneck_stride}
      - ${generic_stride}
      - ${generic_stride}
    activation:
      - ${activation}
      - ${activation}
      - ${activation}
      - "tanh"
  
  critic:
    _target_: retinal_rl.models.circuits.fully_connected.FullyConnected
    output_shape: [1] # TODO: Output shape for Critic and Actor should be automatically determined
    hidden_units: []
    activation: null

  actor:
    _target_: retinal_rl.models.circuits.fully_connected.FullyConnected
    output_shape: [6]
    hidden_units: []
    activation: null
